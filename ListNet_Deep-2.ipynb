{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import ast\n",
    "import time\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=pd.read_csv('score.csv',header=None)\n",
    "job_feature=pd.read_csv('job_feature1.csv',index_col=False)\n",
    "query_feature=pd.read_csv('query_feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.columns=['jobno','querystring','y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_feature=job_feature.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_feature=query_feature.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train-click.json','r') as f:\n",
    "    a=f.readlines()\n",
    "Lis=[ast.literal_eval(i) for i in a]\n",
    "Lis=[{'joblist':i['joblist'],'querystring':i['querystring']} for i in Lis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_variable(lis,query):\n",
    "    #1 把list中每個元素都找到job_feature並與query join\n",
    "    #2 計算出每個query對應到job的rel分數，若沒有值補0\n",
    "    d = {'jobno': [int(i) for i in lis], 'querystring': [query for i in lis]}\n",
    "    dat = pd.merge(pd.DataFrame(d), score, how='left', on=['jobno','querystring']).fillna(0)\n",
    "    #3 merge-job feature\n",
    "    dat = pd.merge(pd.DataFrame(dat), job_feature, how='left', on=['jobno']).fillna(0)\n",
    "    #4 merge query feature\n",
    "    dat = pd.merge(pd.DataFrame(dat), query_feature, how='left', on=['querystring']).fillna(0)\n",
    "    \n",
    "    return np.array(dat['y']),np.array(dat.iloc[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListNet():\n",
    "    def __init__(self,learning_rate=0.01,list_size=20,query_feature_size=42,job_feature_size=0):\n",
    "        tf.reset_default_graph()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.list_size = list_size \n",
    "        self.query_feature_size=query_feature_size\n",
    "        self.job_feature_size=job_feature_size\n",
    "        # tf Graph input\n",
    "        self.x = tf.placeholder(tf.float32, [self.list_size, self.query_feature_size+self.job_feature_size])\n",
    "        self.y = tf.placeholder(tf.float32, [self.list_size])\n",
    "        # Create autoencoder network\n",
    "        self._create_network()\n",
    "        # Define loss function based variational upper-bound and \n",
    "        # corresponding optimizer\n",
    "        self._create_loss_optimizer()\n",
    "        \n",
    "        # Initializing the tensor flow variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        # Launch the session\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(init)\n",
    "        self.saver = tf.train.Saver(max_to_keep=100)\n",
    "    \n",
    "    def _create_network(self):\n",
    "        # encoder -> 把x encode成 z ->把z encode成mu,sigma \n",
    "        network_weights=self._initialize_weights()\n",
    "        \n",
    "        layer1=tf.add(tf.matmul(self.x,network_weights['weights']['Deep1']),network_weights['b']['Deep1'])\n",
    "        layer1=tf.sigmoid(layer1)\n",
    "        \n",
    "        layer2=tf.add(tf.matmul(layer1,network_weights['weights']['Deep2']),network_weights['b']['Deep2'])\n",
    "        layer2=tf.sigmoid(layer2)\n",
    "        \n",
    "        self.t=tf.add(tf.matmul(layer2,network_weights['weights']['out']),network_weights['b']['out'])\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        all_weights={\n",
    "                \"weights\":{\n",
    "                    \"Deep1\":tf.get_variable('C_W_1', shape=(self.query_feature_size+self.job_feature_size,10), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "                    \"Deep2\":tf.get_variable('C_W_2', shape=(10,5), initializer=tf.contrib.layers.xavier_initializer()) ,\n",
    "                    \"out\":tf.get_variable('out_w', shape=(5,1), initializer=tf.contrib.layers.xavier_initializer()) \n",
    "                },\n",
    "                \"b\":{\n",
    "                    \"Deep1\":tf.get_variable('C_b_1', shape=(10), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "                    \"Deep2\":tf.get_variable('C_b_2', shape=(5), initializer=tf.contrib.layers.xavier_initializer()) ,\n",
    "                    \"out\":tf.get_variable('out_b', shape=(1), initializer=tf.contrib.layers.xavier_initializer()) \n",
    "                }\n",
    "            }\n",
    "        return all_weights\n",
    "    \n",
    "    def _create_loss_optimizer(self):\n",
    "        real_score=tf.divide(tf.exp(self.y),tf.reduce_sum(tf.exp(self.y)))\n",
    "        model_score=tf.divide(tf.exp(self.t),tf.reduce_sum(tf.exp(self.t)))\n",
    "        self.cost = -tf.reduce_sum(tf.multiply(real_score,tf.log(model_score)))\n",
    "        self.optimizer = \\\n",
    "            tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "    \n",
    "    def partial_fit(self, X,Y):\n",
    "        \"\"\"Train model based on mini-batch of input data.\n",
    "\n",
    "        Return cost of mini-batch.\n",
    "        \"\"\"\n",
    "        #opt, cost = self.sess.run((self.optimizer, self.cost), \n",
    "    #                                   feed_dict={self.x: X})\n",
    "        opt,cost=self.sess.run((self.optimizer,self.cost),{self.x:X,self.y:Y})\n",
    "        return cost\n",
    "    \n",
    "    def restore_model(self,checkpoint):\n",
    "        self.saver.restore(self.sess,checkpoint)\n",
    "    \n",
    "    def predict(self,List,query):\n",
    "        _,x=get_variable(List,query)\n",
    "        sort_list=self.sess.run(self.t,{self.x:x})\n",
    "        sort_list=pd.DataFrame({\"index\":sort_list.flatten(),\"joblist\":List})\n",
    "        return  sort_list.sort_values(by=['index'])\n",
    "    \n",
    "    def NDCG(self,List,query):\n",
    "        y,x=get_variable(List,query)\n",
    "        sort_list=self.sess.run(self.t,{self.x:x})\n",
    "        sort_list=pd.DataFrame({\"index\":sort_list.flatten(),\"joblist\":List})\n",
    "        sort_list=sort_list.sort_values(by=['index'])\n",
    "        sort_true=pd.DataFrame({\"index\":y,\"joblist\":List})\n",
    "        sort_true=sort_true.sort_values(by=['index'])\n",
    "        sort_true['fake']=sort_list['joblist']\n",
    "        DCG=pd.merge(sort_list,sort_true,on=\"joblist\",how=\"left\")\n",
    "        print(DCG['index_y'])\n",
    "        DCG=self.discount_rel(list(DCG['index_y']))\n",
    "        IDCG=sorted(y,reverse=True)\n",
    "        print(IDCG)\n",
    "        IDCG=self.discount_rel(IDCG)\n",
    "        return DCG/IDCG\n",
    "        \n",
    "    def discount_rel(self,lis):\n",
    "        return np.sum([lis[i]/np.log2(i+2) for i in range(len(lis))])\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( learning_rate=0.01,\n",
    "          batch_size=2000, training_epochs=10, display_step=5):\n",
    "    listnet = ListNet()\n",
    "    # Training cycle\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        # Loop over all batches\n",
    "        tStart = time.time()\n",
    "        disp=0\n",
    "        for i in Lis:\n",
    "#             print(batch_xs.shape)\n",
    "            # Fit training using batch data\n",
    "            Y,X=get_variable(i['joblist'],i['querystring'])\n",
    "            \n",
    "            cost = listnet.partial_fit(X,Y)       \n",
    "            disp+=1\n",
    "            if disp%display_step*100==0:\n",
    "                print(\"Epoch:\", '[%04d]' % (epoch+1))\n",
    "                print(\"cost=\", \"{:.9f}\".format(cost)) \n",
    "                listnet.saver.save(listnet.sess, \"checkpoints/i_l.ckpt\")\n",
    "    \n",
    "                  \n",
    "#         Display logs per epoch step\n",
    "        if epoch % display_step*500 == 0:\n",
    "            tEnd = time.time()\n",
    "            \n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \n",
    "                  \"cost=\", \"{:.9f}\".format(avg_cost),\n",
    "                  \"time=\",tEnd-tStart)\n",
    "        \n",
    "    return ListNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '[0001]')\n",
      "('cost=', '59.915786743')\n",
      "('Epoch:', '[0001]')\n",
      "('cost=', '59.916046143')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-d0fd4bbd58bd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(learning_rate, batch_size, training_epochs, display_step)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#             print(batch_xs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# Fit training using batch data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'joblist'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'querystring'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-a1f2d415b72d>\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(lis, query)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#2 計算出每個query對應到job的rel分數，若沒有值補0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'jobno'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'querystring'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jobno'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'querystring'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#3 merge-job feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'jobno'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/reshape/merge.pyc\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     56\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                          validate=validate)\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/reshape/merge.pyc\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 self.left, self.right)\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/reshape/merge.pyc\u001b[0m in \u001b[0;36m_get_join_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             (left_indexer,\n\u001b[0;32m--> 748\u001b[0;31m              right_indexer) = self._get_join_indexers()\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/reshape/merge.pyc\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                                   \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                                   how=self.how)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/reshape/merge.pyc\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[0;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[0;31m# `count` is the num. of unique keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;31m# set(lkey) | set(rkey) == range(count)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m     \u001b[0mlkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m     \u001b[0;31m# preserve left frame order if how == 'left' and sort == False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/reshape/merge.pyc\u001b[0m in \u001b[0;36m_factorize_keys\u001b[0;34m(lk, rk, sort)\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0mllab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m     \u001b[0mrlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable.pyx\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64Factorizer.factorize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_labels\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \"\"\"Convert the input to an array.\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisnet=ListNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i_l.ckpt\n"
     ]
    }
   ],
   "source": [
    "lisnet.restore_model(tf.train.latest_checkpoint('checkpoints'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1.0\n",
      "1     0.0\n",
      "2     0.0\n",
      "3     1.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "6     0.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    0.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    0.0\n",
      "18    2.0\n",
      "19    0.0\n",
      "Name: index_y, dtype: float64\n",
      "[2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.60475102714555273"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lisnet.NDCG(Lis[0]['joblist'],Lis[0]['querystring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.0\n",
      "1     0.0\n",
      "2     1.0\n",
      "3     0.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "6     0.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    0.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "19    0.0\n",
      "Name: index_y, dtype: float64\n",
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('NDCG:', 0.5)\n",
      "0     0.0\n",
      "1     0.0\n",
      "2     1.0\n",
      "3     0.0\n",
      "4     1.0\n",
      "5     1.0\n",
      "6     0.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    0.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "19    0.0\n",
      "Name: index_y, dtype: float64\n",
      "[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('NDCG:', 0.58334161051493316)\n",
      "0     0.0\n",
      "1     0.0\n",
      "2     0.0\n",
      "3     0.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "6     0.0\n",
      "7     1.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    0.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "19    0.0\n",
      "Name: index_y, dtype: float64\n",
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('NDCG:', 0.31546487678572877)\n",
      "0     0.0\n",
      "1     0.0\n",
      "2     0.0\n",
      "3     0.0\n",
      "4     1.0\n",
      "5     1.0\n",
      "6     0.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    0.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "19    0.0\n",
      "Name: index_y, dtype: float64\n",
      "[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('NDCG:', 0.45560514958746035)\n",
      "0     0.0\n",
      "1     0.0\n",
      "2     0.0\n",
      "3     0.0\n",
      "4     0.0\n",
      "5     1.0\n",
      "6     0.0\n",
      "7     0.0\n",
      "8     1.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    0.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "19    0.0\n",
      "Name: index_y, dtype: float64\n",
      "[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('NDCG:', 0.40298313359773236)\n",
      "0     0.0\n",
      "1     0.0\n",
      "2     0.0\n",
      "3     0.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "6     0.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    1.0\n",
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    0.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "19    0.0\n",
      "Name: index_y, dtype: float64\n",
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('NDCG:', 0.27894294565112987)\n",
      "0     0.0\n",
      "1     0.0\n",
      "2     1.0\n",
      "3     0.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "6     0.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    1.0\n",
      "11    1.0\n",
      "12    2.0\n",
      "13    0.0\n",
      "14    0.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    0.0\n",
      "18    2.0\n",
      "19    1.0\n",
      "Name: index_y, dtype: float64\n",
      "[2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('NDCG:', 0.45889226302926794)\n",
      "0     0.0\n",
      "1     0.0\n",
      "2     0.0\n",
      "3     1.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "6     0.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "11    0.0\n",
      "12    0.0\n",
      "13    0.0\n",
      "14    0.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "19    0.0\n",
      "Name: index_y, dtype: float64\n",
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('NDCG:', 0.43067655807339306)\n",
      "0     1.0\n",
      "1     0.0\n",
      "2     0.0\n",
      "3     0.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "6     0.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "10    0.0\n",
      "11    0.0\n",
      "12    1.0\n",
      "13    0.0\n",
      "14    0.0\n",
      "15    0.0\n",
      "16    0.0\n",
      "17    1.0\n",
      "18    0.0\n",
      "19    0.0\n",
      "Name: index_y, dtype: float64\n",
      "[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "('NDCG:', 0.70300696017457731)\n"
     ]
    }
   ],
   "source": [
    "for i in Lis[1:10]:\n",
    "    print(\"NDCG:\",lisnet.NDCG(i['joblist'],i['querystring']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
